%
% Copyright © 2016 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
%\input{../blogpost.tex}
%\renewcommand{\basename}{vectorproduct}
%%\renewcommand{\dirname}{notes/phy1520/}
%\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%%\newcommand{\dateintitle}{}
%%\newcommand{\keywords}{}
%
%\input{../peeter_prologue_print2.tex}
%
%\usepackage{peeters_layout_exercise}
%\usepackage{peeters_braket}
%\usepackage{peeters_figures}
%\usepackage{siunitx}
%%\usepackage{mhchem} % \ce{}
%%\usepackage{macros_bm} % \bcM
%%\usepackage{macros_qed} % \qedmarker
%%\usepackage{txfonts} % \ointclockwise
%
%\beginArtNoToc
%
%\generatetitle{XXX}
%%\chapter{XXX}
%%\label{chap:vectorproduct}
%
Given two vectors \( \Bx, \By \) the scalar grade of the vector product \( \Bx \By \) was shown (\cref{problem:gradeselection:RnDotProduct}) to be
\begin{equation}\label{eqn:vectorproduct:20}
\gpgradezero{ \Bx \By }
=
\sum_{i = 1}^N x_i y_i
=
\Bx \cdot \By.
\end{equation}

The grade two selection of this product was found (\cref{problem:gradeselection:vectorwedge}) to be

\begin{equation}\label{eqn:vectorproduct:40}
\gpgradetwo{ \Bx \By }
=
\sum_{i < j}
%(x_i y_j - x_j y_i)
\begin{vmatrix}
x_i & x_j \\
y_i & y_j
\end{vmatrix}
\Be_i \Be_j
=
\Bx \wedge \By
=
-\By \wedge \Bx.
\end{equation}

The reader should convince themself that the vector product \( \Bx \By \) has only even grades (0,2), and can therefore be expanded as

\begin{dmath}\label{eqn:vectorproduct:60}
\Bx \By
=
\gpgradezero{ \Bx \By }
+
\gpgradetwo{ \Bx \By },
\end{dmath}

or
\boxedEquation{eqn:vectorproduct:80}{
\Bx \By
=
\Bx \cdot \By
+
\Bx \wedge \By.
}

This is a fundamental and very useful relationship.  In these notes this is a consequence of the axioms and the generalized definitions of the dot and wedge products.  Some authors will use this to define the geometric product of two vectors.

When considering the Euclidean space \R{3}, an additional relationship follows (\cref{problem:gradeselection:WedgeRelationshipToCrossProduct}), which is also incredibly useful

\boxedEquation{eqn:vectorproduct:100}{
\Bx \By
=
\Bx \cdot \By
+
I
(\Bx \cross \By).
}

Note that this is the GA equivalent of the Pauli relationship \cref{eqn:GAmotivation:120} that will be familiar to a student of quantum spin states.
The ability to combine dot and cross product relationships into a single multivector equation is not just a theoretical nicety.  This happens to also be the reason that GA is so applicable to the study of electromagnetism.   To illustrate this, and provide a hint of things to come, consider the GA formulation of the electrostatic and magnetostatic Maxwell equations.

\makeexample{Electrostatic and magnetostatics.}{example:vectorproduct:electrostatics}{

With no magnetic current, no magnetic sources, and no time derivatives, Maxwell's equations in simple media take the form

\begin{dmath}\label{eqn:vectorproduct:120}
\begin{aligned}
\spacegrad \cdot \BB &= 0 \\
\spacegrad \cross \BB &= \mu \BJ \\
\spacegrad \cross \BE &= 0 \\
\spacegrad \cdot \BE &= \frac{\rho}{\epsilon}.
\end{aligned}
\end{dmath}

For electrostatic conditions \( \BJ = 0 \), so using \cref{eqn:vectorproduct:100} the first and last equations can be combined into a single first order homogeneous multivector gradient equation

\begin{equation}\label{eqn:vectorproduct:140}
\spacegrad \BB
=
\spacegrad \cdot \BB +I (\spacegrad \cross \BB )
=
0.
\end{equation}

The electric gradient equation is

\begin{equation}\label{eqn:vectorproduct:160}
\spacegrad \BE
=
\spacegrad \cdot \BE +I (\spacegrad \cross \BE )
=
\frac{\rho}{\epsilon}.
\end{equation}

Maxwell's equations are reduced to two multivector equations with this transformation
\begin{dmath}\label{eqn:vectorproduct:180}
\begin{aligned}
\spacegrad \BE &= \frac{\rho}{\epsilon} \\
\spacegrad \BB &= 0.
\end{aligned}
\end{dmath}

For magnetostatics \( \rho = 0 \), and the same assembly of Maxwell's equations gives

\begin{dmath}\label{eqn:vectorproduct:220}
\begin{aligned}
\spacegrad \BB &= I \mu \BJ \\
\spacegrad \BE &= 0.
\end{aligned}
\end{dmath}

It will be seen later that it is actually more natural to express magnetic fields as a bivector \( I \BB \).  Using \( I^2 = -1 \) (\cref{problem:gradeselection:R3PseudoscalarSquare}) the magnetostatic equation takes the form

\begin{dmath}\label{eqn:vectorproduct:240}
\spacegrad (I \BB) = - \mu \BJ.
\end{dmath}

Both the electrostatic and magnetostatic equations can be solved directly using the Green's function for the gradient, producing the Coulomb integral for the electric field and Biot-Savart's law for the magnetic field.
Before demonstrating this, the concepts required to attack multivector integrals must be formulated.
} % example

Using \cref{problem:gradeselection:dotprod} and \cref{eqn:vectorproduct:80} it can be shown that the wedge product is an explicit antisymmetrized sum of vector products, just as the dot product is the symmetrized vector product sum

\boxedEquation{eqn:vectorproduct:300}{
\begin{aligned}
\Bx \cdot \By &= \inv{2} \lr{ \Bx \By + \By \Bx } \\
\Bx \wedge \By &= \inv{2} \lr{ \Bx \By - \By \Bx }
\end{aligned}
}

Some authors will use these as the respective definitions of the dot and wedge products.

The non-commutative nature of the vector product was one of the first observed consequences of the axioms.  The vector product is also not generally anticommutative, as was the case for normal vectors.  Rearranging \cref{eqn:vectorproduct:300} provides the general commutation identity for two vectors

%\begin{dmath}\label{eqn:vectorproduct:320}
\boxedEquation{eqn:vectorproduct:320}{
\By \Bx = 2 \Bx \cdot \By - \Bx \By.
}
%\end{dmath}

Observe that when the vectors are perpendicular, the strict anticommutation result follows.
This can be a handy tool for abstract multivector expression manipulation.


%}
%\EndNoBibArticle
