%\chapter{Multivector spaces}
\section{Multivectors}

\subsection{Multivector space.}

The first lesson that must be learned in the study in GA, is to unlearn claims
%\footnote{I heard such claims from high school math and physics teachers.}
that vectors cannot be multiplied.
Instead we start by assuming that a multiplication operation between any number of vectors can be defined,
and that sums, called multivectors, of scalars, vectors, and any products of vectors are also well defined.
These rules are formalized in the definition of a multivector space.

\makedefinition{Multivector space.}{def:multiplication:multivectorspace}{
   Given a (generating) vector space \( V \) with a basis \( \setlr{ \Bx_1, \Bx_2, \cdots } \), a multivector is any sum

   \( a_0 + \sum_i a_i \Bx_i + \sum_{ij} a_{ij} \Bx_i \Bx_j + \sum_{ijk} a_{ijk} \Bx_i \Bx_j \Bx_k + \cdots \), where \( a_0, a_i, a_{ij}, \cdots \) are scalars,
and vector multiplication is represented by juxtaposition.

   A multivector space is a set \( M = \setlr{ x, y, z, \cdots } \) of multivectors, where the following axioms are satisfied

\begin{tcolorbox}[tab2,tabularx={X|Y},title=Multivector space axioms.,boxrule=0.5pt]
    Contraction. & \( \Bx^2 = \Bx \cdot \Bx, \forall \Bx \in V \) \\ \hline
    Addition is closed. & \( x + y \in M \) \\ \hline
    Multiplication is closed. & \( x y \in M \) \\ \hline
    Addition is associative. & \( (x + y) + z = x + (y + z) \) \\ \hline
    Addition is commutative. & \( y + x = x + y \) \\ \hline
    There exists a zero element \( 0 \in M \).  & \( x + 0 = x \) \\ \hline
    There exists a negative additive inverse \( -x \in M \). & \( x + (-x) = 0 \) \\ \hline
    Multiplication is distributive.  & \( x( y + z ) = x y + x z \), \( (x + y)z = x z + y z \) \\ \hline
    Multiplication is associative. & \( (x y) z = x ( y z ) \) \\ \hline
    There exists a multiplicative identity \( 1 \). & \( 1 x = x \) \\ \hline
\end{tcolorbox}
}

Compared to the vector space, def'n. \ref{def:prerequisites:vectorspace}, the multivector space

\begin{itemize}
\item presumes a vector multiplication operation, which is not assumed to be commutative (order matters),
\item generalizes vector addition to multivector addition,
\item generalizes scalar multiplication to multivector multiplication (of which scalar multiplication is a special case),
\item and most importantly, specifies a rule providing the meaning of a squared vector (the contraction axiom).
\end{itemize}

The contraction axiom is arguably the most important of the multivector space axioms, since multiplicative closure would not be possible without it.
The remaining set of non-contraction axioms of a multivector space are almost that of a field
\footnote{A mathematician would call a multivector space a non-commutative ring with identity \citep{van1943modern}, and could state the multivector space definition much more compactly without listing all those properties explicitly.}
(as encountered in the study of complex inner products),
as they describe most of the properties one
would expect of a ``well behaved'' set of number-like quantities.
However, a field also requires a multiplicitive inverse element for all elements of the space, which exists for some multivector subspaces, but not in general.

%These axioms may seem simple enough, especially since they are not that different from the familiar axioms of the vector space,
%but it will take considerable work to extract all their consequences.
%The subject of Geometric Algebra can be viewed as the study of the impliciations of the axioms
%of the multivector space.

\subsection{Nomenclature.}

Some nomenclature and notation is helpful before systematically examining the implications of the multivector space axioms.

\makedefinition{Blade and grade}{def:multiplication:blade}{
A product of \( k \) perpendicular vectors is called a k-blade, or a blade of grade \( k \).
A grade zero blade is a scalar.

The notation \( F \in \bigwedge^k \) is used in the literature to indicate that \( F \) is a blade of grade \( k \).
}

The maximum grade of a multivector is equal to the dimension of the generating vector space.
For example, for a multivector space generated by \R{3}, no k-vector can have grade greater than 3.

Examples of blades with grades 0, 1, 2, and 3 respectively are

\begin{dmath}\label{eqn:multivector:180}
\begin{aligned}
&1 \\
&\Be_1,\quad \Be_2,\quad \Be_3 \\
&\Be_1 \Be_2,\quad \Be_2 \Be_1,\quad \Be_1 \Be_2 + \Be_2 \Be_3 \\
&\Be_1 \Be_2 \Be_3,\quad \Be_1 \Be_3 \Be_2,\quad \Be_1 \Be_4 \Be_2
\end{aligned}
\end{dmath}

Multivectors which can be factored into perpendicular vector products, such as
\begin{dmath}\label{eqn:multiplication:220}
\Be_1 \Be_2 + 3 \Be_1 \Be_3
=
\Be_1 (\Be_2 + 3 \Be_3),
\end{dmath}

are blades.  In contrast, the following grade 2 multivectors

\begin{dmath}\label{eqn:multiplication:240}
\Be_1 \Be_2 + \Be_3 \Be_4,
\end{dmath}

and
\begin{dmath}\label{eqn:multiplication:260}
\Be_1 \Be_2 + \Be_2 \Be_3 + \Be_3 \Be_1,
\end{dmath}

which cannot be factored into two vector products, are not blades.

\makedefinition{k-vector.}{dfn:multivector:kvector}{
A sum of k-blades is called a k-vector.
} % definition

Multivectors are therefore sums of k-vectors with different grades.

Add the k-blade examples above are also k-vectors.
K-vectors with grades 2 and 3 are so pervasive that they are given special names.

\makedefinition{Bivector.}{dfn:multivector:bivector}{
A bivector, or 2-vector, is a k-vector with grade 2.
} % definition

The product \( \Be_1 \Be_2 \) is a bivector, as is \( \Be_2 \Be_3 + 3 \Be_4 \Be_1 \)
%Each of \( \Be_1 \Be_2, \Be_2 \Be_1, \Be_1 \Be_2 + \Be_2 \Be_3 \), and \( \Be_1 \Be_2 + \Be_3 \Be_4 \) are bivectors.
%All but the last of these represents an oriented plane segment.

\makedefinition{Trivector.}{dfn:multivector:trivector}{
A trivector, or 3-vector, is a k-vector with grade 3.
} % definition

%Quantities with higher grades than 3 are not generally given explicit names.
The multivector \( \Be_3 \Be_1 \Be_2 \) is a trivector, as is \( \Be_1 \Be_2 \Be_3 + 3 \Be_5 \Be_4 \Be_1 \).  The latter is not a blade.
%Each of \( \Be_1 \Be_2 \Be_3, \Be_1 \Be_3 \Be_2, \Be_1 \Be_4 \Be_2 \) are trivectors.
% , and represent oriented volumes.

\makedefinition{Grade selection operator}{dfn:gradeselection:gradeselection}{
Given a set of k-vectors \( M_k, k \in [0,N] \), and any multivector of their sum

\begin{equation*}
M = \sum_{i = 0}^N M_i,
\end{equation*}

the grade selection operator is defined as

\begin{equation*}\label{eqn:gradeselection:40}
\gpgrade{M}{k} \equiv M_k.
\end{equation*}

Due to its importance, selection of the (scalar) zero grade is given the shorthand
\begin{equation*}
\gpgradezero{M} \equiv \gpgrade{M}{0} = M_0.
\end{equation*}
}

For example, if \( M = 3 - \Be_3 + 2 \Be_1 \Be_2 \), then
\begin{equation}\label{eqn:gradeselection:80}
\begin{aligned}
\gpgradezero{M} &= 3 \\
\gpgrade{M}{1} &= - \Be_3 \\
\gpgrade{M}{2} &= 2 \Be_1 \Be_2 \\
\gpgrade{M}{3} &= 0.
\end{aligned}
\end{equation}

\makedefinition{Orthonormal product shorthand.}{dfn:multivector:shorthand}{
Given an orthonormal basis \( \setlr{ \Be_1, \Be_2, \cdots } \), a multiple indexed quantity \( \Be_{ij\cdots k} \) should be interpretted as the product (in the same order) of the basis elements with those indexes

\begin{equation*}
\Be_{ij\cdots k} = \Be_i \Be_j \cdots \Be_k.
\end{equation*}
} % definition

For example,

\begin{equation}\label{eqn:multivector:n}
\begin{aligned}
\Be_{12} &= \Be_1 \Be_2 \\
\Be_{123} &= \Be_1 \Be_2 \Be_3 \\
\Be_{23121} &= \Be_2 \Be_3 \Be_1 \Be_2 \Be_1.
\end{aligned}
\end{equation}

\subsection{Unpacking the axioms.}

Unless otherwise stated, a Euclidean vector space with an orthonormal basis \( \setlr{\Be_1, \Be_2, \cdots } \) is assumed for the remainder of this chapter.
Generalizations required for non-Euclidean spaces will be discussed when spacetime vectors are introduced.
%  At that point, it is a good exersize for the reader to come back to this, and determine where any result

\subsubsection{Colinear vectors.}

It was pointed out that the vector multiplication operation was not assumed to be commutative (order matters).  The only condition for which the product of two vectors is order independent, is when those vectors are colinear.

\maketheorem{Commutation}{thm:multiplication:anticommutationNormal}{
Let \(\Bu\), and \(\Bv\) be two non-zero colinear vectors.  The product of these vectors commute (is unchanged by interchange).

\begin{equation*}
\Bu \Bv = \Bv \Bu.
\end{equation*}
} % theorem

The proof is simple.  Because these vectors are colinear there exists some \( \alpha \) for which \( \Bv = \alpha \Bu \), so

\begin{dmath}\label{eqn:multivector:n}
\Bv \Bu
=
\alpha \Bu \Bu
=
\Bu \alpha \Bu
=
\Bu \Bv.
\end{dmath}

Also observe that, because of the contraction axiom, the product of two colinear vectors is a scalar.  In particular, the square of a unit vector is unity, something that should be highlighted explicitly, since this property will be used again and again
%\begin{equation}\label{eqn:multiplication:300}
\boxedEquation{eqn:multiplication:320}{
\xcap^2 = 1.
}
%\end{equation}

For example, the squares of any orthonormal basis vectors are unity \( \Be_1^2 = \Be_2^2 = \Be^3 = 1 \).

A corollory of this is that any scalar can also be factored into a product of two colinear vectors.
In particular, the square \( 1 \) can be factored into the square of any unit vector

\boxedEquation{eqn:multiplication:n}{
1 = \xcap \xcap.
}

This has been highlighted explicitly, because this factorization trick will be used repeatedly.

\subsubsection{Normal vectors.}

The simplest bivectors are products of two different orthonormal vectors.  For \R{3} all such bivectors that can be formed from the basis elements are \( \Be_1 \Be_2, \Be_2 \Be_1, \Be_2 \Be_3, \Be_3 \Be_2, \Be_3 \Be_1, \Be_1 \Be_3 \).

It turns out that these are not all independent.  To see this, consider the square of the vector \( \Be_1 + \Be_2 \),
as sketched in \cref{fig:unitSum:unitSumFig1}.
\imageFigure{../figures/GAelectrodynamics/unitSumFig1}{\( \Be_1 + \Be_2 \).}{fig:unitSum:unitSumFig1}{0.3}
By the contraction axiom, the square of this vector is \( 2 \)

\begin{dmath}\label{eqn:multivector:n}
\lr{ \Be_1 + \Be_2 }^2 = 2.
\end{dmath}

Computing this same square by expansion should give the same result

\begin{dmath}\label{eqn:gaTutorial:80}
(\Be_1 + \Be_2)^2
= (\Be_1 + \Be_2)(\Be_1 + \Be_2)
= \Be_1^2 + \Be_2 \Be_1 + \Be_1 \Be_2 + \Be_2^2
= 1 + \Be_2 \Be_1 + \Be_1 \Be_2 + 1
= 2 + \Be_2 \Be_1 + \Be_1 \Be_2.
\end{dmath}

This expanded RHS is a mixed grade multivector with grades zero and two, however, it must equal \( 2 \).
The only possible solution requires that the grade two components of this equation are zero

\begin{dmath}\label{eqn:multivector:280}
\Be_2 \Be_1 + \Be_1 \Be_2 = 0,
\end{dmath}

or
%\begin{dmath}\label{eqn:multiplication:140}
\boxedEquation{eqn:multiplication:140}{
\Be_1 \Be_2 = -\Be_1 \Be_2.
}
%\end{dmath}

The same computation could have been performed for any two orthonormal vectors, so we conclude that any interchange of two orthonormal vectors changes the sign.  In general this is true of any normal vectors.

\maketheorem{Anticommutation}{thm:multiplication:anticommutationNormal}{
Let \(\Bu\), and \(\Bv\) be two normal vectors, the product of which \( \Bu \Bv \) is a bivector.
Changing the order of these products toggles the sign of the bivector.

\begin{equation*}
\Bu \Bv = -\Bv \Bu.
\end{equation*}

This sign change on interchange is called anticommutation.
} % theorem

\subsection{Irreducible products}

Armed with the contraction axiom and \cref{eqn:multiplication:140} it is now possible to show how to put a multivector into an irreducible form.  As an example, consider

\begin{equation}\label{eqn:SimpleProducts:20}
M = \Be_3 \Be_3 + 2 \Be_1 \Be_2 \Be_1 + \Be_2 \Be_3 - 5 \Be_3 \Be_1 \Be_3 \Be_2 + \Be_4 \Be_1 \Be_4 \Be_2 \Be_3 + \Be_1 \Be_2 \Be_1 \Be_3 \Be_4 \Be_5.
\end{equation}

Application of the contraction axiom shows that the first term is a scalar

\begin{equation}\label{eqn:SimpleProducts:40}
\Be_3 \Be_3 = 1.
\end{equation}

The second term is a vector, as it is possible to reorder normal products (changing sign each time) and regroup terms to apply the contraction axiom, as follows

\begin{dmath}\label{eqn:SimpleProducts:60}
2 \Be_1 \Be_2 \Be_1
=
2 \Be_1 \lr{ \Be_2 \Be_1 }
=
2 \Be_1 \lr{ - \Be_1 \Be_2 }
=
-2 \Be_1 \Be_1 \Be_2
=
-2 \lr{ \Be_1 \Be_1 } \Be_2
=
-2 \Be_2.
\end{dmath}

The third term is a bivector and cannot be reduced further.  The fourth term is also a bivector

\begin{dmath}\label{eqn:SimpleProducts:80}
- 5 \Be_3 \Be_1 \Be_3 \Be_2
=
- 5 \lr{ \Be_3 \Be_1 } \Be_3 \Be_2
=
+ 5 \lr{ \Be_1 \Be_3 } \Be_3 \Be_2
=
+ 5 \Be_1 \lr{ \Be_3 \Be_3 } \Be_2
=
+ 5 \Be_1 \Be_2.
\end{dmath}

As the fifth term has repeated indexes, is is also reducible too

\begin{dmath}\label{eqn:SimpleProducts:100}
\Be_4 \Be_1 \Be_4 \Be_2 \Be_3
=
\lr{ \Be_4 \Be_1} \Be_4 \Be_2 \Be_3
=
-\lr{ \Be_1 \Be_4} \Be_4 \Be_2 \Be_3
=
- \Be_1 \lr{ \Be_4 \Be_4 } \Be_2 \Be_3
=
- \Be_1 \Be_2 \Be_3.
\end{dmath}

The reader should demonstrate that the final term has grade four, and can be reduced to \( -\Be_2 \Be_3 \Be_4 \Be_5 \).

\begin{dmath}\label{eqn:SimpleProducts:120}
M = 1 - 2 \Be_2  + \Be_2 \Be_3 + 5 \Be_1 \Be_2 - \Be_1 \Be_2 \Be_3 -\Be_2 \Be_3 \Be_4 \Be_5.
  = 1 - 2 \Be_2  + \Be_{23} + 5 \Be_{12} - \Be_{123} -\Be_{2345}.
\end{dmath}

\subsection{Mixed grade sums}
In traditional vector algebra, the
``weird'' sum of a scalar and vector is forbidden and undefined, but is explicitly allowed in GA.  For example,

\begin{dmath}\label{eqn:multivector:240}
1 + \Be_1,
\end{dmath}

is a simple mixed grade multivector.
Such mixed grade mathematical objects are not only well defined in GA, but are required to represent some vector products.  One of the simplest examples is the following vector product

\begin{dmath}\label{eqn:multivector:260}
\Be_1 ( \Be_1 + \Be_2 )
=
\Be_1 \Be_1 + \Be_1 \Be_2
=
\Be_1 \cdot \Be_1 + \Be_1 \Be_2
=
1 + \Be_1 \Be_2,
\end{dmath}

where the last step assumes the vector space is Euclidean.

\subsection{Nomenclature: pseudoscalar and reverse.}

\makedefinition{Pseudoscalar.}{def:multiplication:pseudoscalar}{
A blade with grade that matches the dimension of the space.
}

In a two dimensional space \( \Be_1 \Be_2 \) is a pseudoscalar, as is \( 3 \Be_2 \Be_1 \).  In a three dimensional space
\( \Be_3 \Be_1 \Be_2 \) is a pseudoscalar, as is \( - 7 \Be_3 \Be_1 (\Be_2 + \Be_3 ) \).
%A pseudoscalar has an implied orientation, which can be
%associated with the handedness of the underlying basis.
It is conventional to refer to

\begin{dmath}\label{eqn:definitions:320}
i = \Be_1 \Be_2,
\end{dmath}

as ``the pseudoscalar'' for a two dimensional space, and to

\begin{dmath}\label{eqn:definitions:340}
I = \Be_1 \Be_2 \Be_3,
\end{dmath}

as ``the pseudoscalar'' for a three dimensional space.

% relative path because this is shared with gabookI
\input{../GAelectrodynamics/reverseDefined.tex}

Given a k-blade \( A_k = \Ba_1 \Ba_2 \cdots \Ba_k \), then

\begin{dmath}\label{eqn:scalarPermutation:81}
\begin{aligned}
A_k^\dagger
&= \Ba_k \Ba_{k-1} \cdots \Ba_1 \\
&= (-1)^{k-1} \Ba_1 \Ba_k \Ba_{k-1} \cdots \Ba_2 \\
&= (-1)^{k-1} (-1)^{k-2} \Ba_1 \Ba_2 \Ba_k \Ba_{k-1} \cdots \Ba_3 \\
&\vdots \\
&= (-1)^{k-1} (-1)^{k-2} \cdots (-1)^1 \Ba_1 \Ba_2 \cdots \Ba_k,
\end{aligned}
\end{dmath}

or
\begin{dmath}\label{eqn:scalarPermutation:101}
A_k^\dagger = (-1)^{k(k-1)/2} A_k.
\end{dmath}

\subsection{Problems}

\makeproblem{One dimensional multivector space.}{problem:multivector:40}{
   Verify that for \( c, d \in \bbR \) the set \( M = \setlr{ c + d \Be_1 } \) satisifies all the multivector axioms.
} % problem

\makeproblem{Normal anticommutation.}{problem:multiplication:anticommutationNormal}{
Prove \cref{thm:multiplication:anticommutationNormal}.
}

