

An important example of the generalized dot product is the dot product of a vector and bivector.
Unlike the dot product of two vectors, a vector-bivector dot product is order dependent.

The vector dot product is zero when the two vectors are normal.
This is also true if the vector and bivector are normal, that is, having no common factor, as in

\begin{equation}\label{eqn:generalizedDot:661}
\Be_1 \cdot \Be_{23} = \gpgradeone{ \Be_{123} } = 0.
\end{equation}

On the other hand, a non-zero vector-bivector dot product requires the vector to have some overlap with the bivector.
A bivector formed from the product of two normal vectors \( B = \Ba \Bb, \, \Ba \cdot \Bb = 0 \), will have a non-zero dot product with any vector that lies in \( \Span \setlr{ \Ba, \Bb} \)

\begin{dmath}\label{eqn:generalizedDot:681}
\lr{ \alpha \Ba + \beta \Bb } \cdot (\Ba\Bb)
=
\alpha \Norm{\Ba}^2 \Bb - \beta \Norm{\Bb}^2 \Ba.
\end{dmath}

There is a direct relationship between the
dot product of a vector and wedge of two vectors with a familiar equivalent in \R{3} vector algebra.
That expansion is

\maketheorem{Dot product of vector and wedge product.}{thm:generalizedDot:wedgeDotDistribution}{
The dot product of a vector and a wedge product of two vectors distributes as
\begin{equation*}
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bc \wedge \Bb } \cdot \Ba
=
( \Ba \cdot \Bb ) \Bc
-( \Ba \cdot \Bc ) \Bb.
\end{equation*}
} % theorem

There are (somewhat tricky) coordinate free ways to prove this theorem, but a dumber simple expansion in coordinates also does the job.

\begin{dmath}\label{eqn:gradeselectionProblems:681}
\begin{aligned}
\Ba \cdot \lr{ \Bb \wedge \Bc } &= \sum_{i, j, k} a_i b_j c_k \Be_i \cdot (\Be_j \wedge \Be_k)
= \sum_{i, j \ne k} a_i b_j c_k \gpgradeone{ \Be_i \Be_j \Be_k }
\\
\lr{ \Bc \wedge \Bb } \cdot \Ba &= \sum_{i, j, k} a_i b_j c_k (\Be_k \wedge \Be_j) \cdot \Be_i
= \sum_{i, j \ne k} a_i b_j c_k \gpgradeone{ \Be_k \Be_j \Be_i }
\end{aligned}
\end{dmath}

If all of \( i, j, k \) are unique then \( \gpgradeone{ \Be_i \Be_j \Be_k } = 0 \), so the vector selection is non-zero only when \( i \) equals one of \( j, k \).
For example

\begin{dmath}\label{eqn:generalizedDot:1040}
\begin{aligned}
\gpgradeone{ \Be_1 \Be_1 \Be_2 } &= \Be_2 \\
\gpgradeone{ \Be_1 \Be_2 \Be_1 } &= -\Be_1.
\end{aligned}
\end{dmath}

Given \( j \ne k \), and \( i = j \) or \( i = k \),  then it is simple to show
(\cref{problem:generalizedDot:distributionUnitVectorsa})
that

\begin{equation}\label{eqn:generalizedDot:1020}
\gpgradeone{ \Be_i \Be_j \Be_k }
= \gpgradeone{ \Be_k \Be_j \Be_i },
\end{equation}

so \( \Ba \cdot \lr{ \Bb \wedge \Bc } = \lr{ \Bc \wedge \Bb } \cdot \Ba \).
Additionally
(\cref{problem:generalizedDot:distributionUnitVectorsb})

\begin{equation}\label{eqn:generalizedDot:980}
\gpgradeone{ \Be_i \Be_j \Be_k }
=
\Be_k \lr{ \Be_j \cdot \Be_i }
-\Be_j \lr{ \Be_k \cdot \Be_i }.
\end{equation}

Plugging \cref{eqn:generalizedDot:980} back into \cref{eqn:gradeselectionProblems:681} proves the theorem

\begin{dmath}\label{eqn:generalizedDot:1060}
\Ba \cdot \lr{ \Bb \wedge \Bc }
= \sum_{i, j, k} a_i b_j c_k \lr{ \Be_k \lr{ \Be_j \cdot \Be_i }
-\Be_j \lr{ \Be_k \cdot \Be_i } }
=
\lr{ \Ba \cdot \Bb } \Bc
- \lr{ \Ba \cdot \Bc } \Bb.
\end{dmath}

The LHS of \cref{eqn:generalizedDot:1060} might look familiar as it is related to the \R{3} triple cross product.
\maketheorem{}{thm:generalizedDot:tripleCross}{
For vectors in \R{3}, the dot product of a vector and vector wedge product can be expressed as a triple cross product
\begin{equation*}
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{equation*}
} % theorem

This can be proven by invoking the well known
identity for the triple cross product
(\citep{jackson1975cew})

\begin{dmath}\label{eqn:generalizedDot:1100}
\Ba \cross ( \Bb \cross \Bc ) = (\Ba \cdot \Bc) \Bb - (\Ba \cdot \Bb) \Bc.
\end{dmath}

Alternatively, it can be proven directly by applying the identity \( \Ba \wedge \Bb = I ( \Ba \cross \Bb ) \) to the vector-bivector product, and then selecting the vector grade

\begin{dmath}\label{eqn:generalizedDot:1000}
\Ba \lr{ \Bb \wedge \Bc }
=
\Ba I \lr{ \Bb \cross \Bc }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
I \lr{ \Ba \wedge \lr{ \Bb \cross \Bc } }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
I^2 \Ba \cross \lr{ \Bb \cross \Bc }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{dmath}

This multivector has a pseudoscalar (grade 3) component, and a vector component, so selecting the grade one component proves the theorem

\begin{equation}\label{eqn:generalizedDot:1080}
\gpgradeone{ \Ba \lr{ \Bb \wedge \Bc } }
=
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{equation}

