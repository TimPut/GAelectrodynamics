%\section{Two dimensions}

\paragraph{Multiplication table}

In a 2D space most of the interesting vector products involve the unit bivector \( \Be_1 \Be_2 \).  A product of a spanning set of normal vectors for a space (or subspace) is called a pseudoscalar for that space (or subspace).  The particular pseudoscalar \( \Be_1 \Be_2 \) will be labelled \textbf{the pseudoscalar}.  Computation shows that multiplication with the pseudoscalar anticommutes with the 2D basis vectors

\begin{dmath}\label{eqn:SimpleProducts2:180}
\begin{aligned}
   \Be_1 \lr{ \Be_1 \Be_2 } &= \lr{ \Be_1 \Be_1 } \Be_2 = \Be_2 \\
   \lr{ \Be_1 \Be_2 } \Be_1 &= -\lr{ \Be_2 \Be_1 } \Be_1 = -\Be_2 \\
\end{aligned}
\end{dmath}

\begin{dmath}\label{eqn:SimpleProducts2:200}
\begin{aligned}
   \Be_2 \lr{ \Be_1 \Be_2 } &= \lr{ -\Be_1 \Be_2 } \Be_2 = -\Be_1 \\
   \lr{ \Be_1 \Be_2 } \Be_2 &= \Be_1 \lr{ \Be_2 \Be_2 } = \Be_1 \\
\end{aligned}
\end{dmath}

The products above are tabulated below.

Observe that in \R{2} the product of any basis vector with a pseudoscalar is normal to the original vector, which is also generally true for any vector in a 2D space, as illustrated in \cref{fig:rotationOfe1:rotationOfe1Fig1}.
\imageTwoFigures
{../figures/GAelectrodynamics/rotationOfe1Fig1}
{../figures/GAelectrodynamics/rotationOfe2Fig1}
{Multiplication by \( \Be_1 \Be_2 \).}{fig:rotationOfe1:rotationOfe1Fig1}{scale=0.5}
%\cref{fig:rotationOfe1:rotationOfe1Fig1}.
%\imageFigure{../figures/GAelectrodynamics/rotationOfe1Fig1}{CAPTION: rotationOfe1Fig1}{fig:rotationOfe1:rotationOfe1Fig1}{0.3}
%\cref{fig:rotationOfe2:rotationOfe2Fig1}.
%\imageFigure{../figures/GAelectrodynamics/rotationOfe2Fig1}{CAPTION: rotationOfe2Fig1}{fig:rotationOfe2:rotationOfe2Fig1}{0.3}
Such a multiplication induces a \( \pi/2 \) rotation, the direction of which depends on the orientation of pseudoscalar, and upon whether the multiplication is performed from the left or the right.  A hint of the rotational nature of such a product can be gleamed by computing the square of the 2D pseudoscalar

\begin{dmath}\label{eqn:SimpleProducts2:220}
   \lr{ \Be_1 \Be_2 }^2
   =
   \Be_1 \Be_2
   \Be_1 \Be_2
   =
   \Be_1 \lr{ \Be_2
   \Be_1 } \Be_2
   =
   \Be_1 \lr{ -\Be_1
   \Be_2 } \Be_2
   =
   -\lr{ \Be_1 \Be_1 }
   \lr{ \Be_2 \Be_2 }
   = -1.
\end{dmath}

This unit bivector is seen to square to minus one like the imaginary in complex algebra.  The reader can confirm easily that this is generally true for any unit bivector \( \Be_i \Be_j, \, i \ne j \).
This is a very convienient fact, and allows ad-hoc construction of complex number like coordinate systems in any given planar subspace.

%\ref{tab:SimpleProducts2:10}.
%FIXME: how to reference a tcolorbox table?
% examples in http://ctan.mirrors.hoobly.com/macros/latex/contrib/tcolorbox/tcolorbox.pdf section 5.1
% requires setting up a counter variable like some of the others (theorem environments)

% various options for prettier than default table:
% https://tex.stackexchange.com/a/135421/15
% https://tex.stackexchange.com/a/298109/15
% https://tex.stackexchange.com/a/112359/15
%\captionedTable{2D Multiplication table.}{tab:SimpleProducts2:10}{
%\begin{tabular}{|l||l|l|l|l|}
%\hline
%        & \( 1 \) & \( \Be_1 \) & \( \Be_2 \) & \( \Be_1 \Be_2 \) \\ \hline
%\( 1 \) & \( 1 \) & \( \Be_1 \) & \( \Be_2 \) & \( \Be_1 \Be_2 \) \\ \hline
%\( \Be_1\) & \( \Be_1 \) & \( 1 \) & \( \Be_1 \Be_2 \) & \( \Be_2 \)\\ \hline
%\( \Be_2\) & \( \Be_2 \) & \( -\Be_1 \Be_2 \) & \( 1 \) & \( -\Be_1 \)\\ \hline
%\( \Be_1 \Be_2\) & \( \Be_1 \Be_2 \) & \( -\Be_2 \) & \( \Be_1 \) & \( -1 \) \\ \hline
%\end{tabular}
%}

%\label{tab:SimpleProducts2:10}
\begin{tcolorbox}[tab2,tabularx={X||Y|Y|Y|Y},title=2D Multiplication table.,boxrule=0.5pt]
        & \( 1 \) & \( \Be_1 \) & \( \Be_2 \) & \( \Be_1 \Be_2 \) \\ \hline
\( 1 \) & \( 1 \) & \( \Be_1 \) & \( \Be_2 \) & \( \Be_1 \Be_2 \) \\ \hline
\( \Be_1\) & \( \Be_1 \) & \( 1 \) & \( \Be_1 \Be_2 \) & \( \Be_2 \)\\ \hline
\( \Be_2\) & \( \Be_2 \) & \( -\Be_1 \Be_2 \) & \( 1 \) & \( -\Be_1 \)\\ \hline
\( \Be_1 \Be_2\) & \( \Be_1 \Be_2 \) & \( -\Be_2 \) & \( \Be_1 \) & \( -1 \) \\ \hline
\end{tcolorbox}

\paragraph{Computing the normal 2D}

Given a coordinate representation of an arbitrary vector in a 2D space

\begin{dmath}\label{eqn:SimpleProducts2:240}
   \Bx = \rho
\begin{bmatrix}
   \cos\theta \\
   \sin\theta \\
\end{bmatrix},
\end{dmath}

after counterclockwise rotation by \( \pi/2 \), the rotated coordinates are

\begin{dmath}\label{eqn:SimpleProducts2:260}
\Bx'
=
\begin{bmatrix}
   0 & -1 \\
   1 & 0 \\
\end{bmatrix}
\begin{bmatrix}
   \cos\theta \\
   \sin\theta \\
\end{bmatrix}
=
\rho
\begin{bmatrix}
   -\sin\theta \\
   \cos\theta
\end{bmatrix}.
\end{dmath}

Expressing this vector in terms of the standard basis

\begin{dmath}\label{eqn:SimpleProducts2:280}
   \Bx = \rho \lr{ \Be_1 \cos\theta + \Be_2 \sin\theta },
\end{dmath}

the same rotation can be observed by right multiplication by the pseudoscalar.

\begin{dmath}\label{eqn:SimpleProducts2:300}
\Bx'
= \rho \lr{ \Be_1 \cos\theta + \Be_2 \sin\theta } \Be_1 \Be_2
= \rho \lr{ \Be_2 \cos\theta - \Be_1 \sin\theta }.
\end{dmath}

This is illustrated in \cref{fig:rotationOfV:rotationOfVFig1}.
\imageFigure{../figures/GAelectrodynamics/rotationOfVFig1}{\( \pi/2\) rotation using pseudoscalar multiplication.}{fig:rotationOfV:rotationOfVFig1}{0.3}

A similar left pseudoscalar multiplication induces a clockwise rotation.
(\cref{problem:left2dimaginarymultiplication:1}).

Just as the imaginary rotates complex numbers, the 2D pseudoscalar rotates vectors, with the cavaet that one must be careful about the order that this multiplication is performed.

\paragraph{Complex numbers and rotations}

The 2D pseudoscalar has been seen to have the characteristics of the complex imaginary.  This analogy can be extended by noting that the following multivector

\begin{dmath}\label{eqn:SimpleProducts2:320}
z = x + \Be_1 \Be_2 y,
\end{dmath}

provides an isomorphic representation of a complex number.  This can be made obvious by introduces the lable \( i = \Be_1 \Be_2 \) for the pseudoscalar, since it has the desired characteristics of the imaginary.

Of particular interest is the complex exponential \( e^{i \theta} \).  Because \( i \) commutes with itself and any scalars Euler's formula

\begin{dmath}\label{eqn:SimpleProducts2:340}
e^{i \theta} = \cos\theta + i \sin\theta,
\end{dmath}

applies equally well with this GA representation of complex numbers.
Having seen that right multiplication of vectors with with the pseudoscalar \( i \) had the effect of inducing a \( \pi/2 \) counterclockwise rotation, it is reasonable to expect that this form of complex exponential will generally rotate a 2D vector.  This can be seen by considering an arbitrarily rotated unit vector, from which a complex exponential can be factored out

\begin{dmath}\label{eqn:SimpleProducts2:940}
\xcap
=
\Be_1 \cos\theta + \Be_2 \sin\theta
=
\Be_1 \cos\theta + \Be_1 \Be_1 \Be_2 \sin\theta
=
\Be_1 \lr{ \cos\theta + \Be_1 \Be_2 \sin\theta }
=
\Be_1 \lr{ \cos\theta + i \sin\theta }
=
\Be_1 e^{i\theta}.
\end{dmath}

Alternatively, for the same vector, a complex exponential can be factored out on the left

\begin{dmath}\label{eqn:SimpleProducts2:960}
\xcap
=
\Be_1 \cos\theta + \Be_2 \sin\theta
=
\Be_1 \cos\theta + \Be_2 \Be_1 \Be_1 \sin\theta
=
\lr{ \cos\theta - \Be_1 \Be_2 \sin\theta } \Be_1
=
\lr{ \cos\theta + i \sin\theta } \Be_1
=
e^{-i\theta} \Be_1.
\end{dmath}

The conclusion is that left multiplication by \( e^{i\theta} \) rotates a vector clockwise, whereas right multiplication with the same complex exponential rotates a vector counterclockwise, as
illustrated in \cref{fig:rotationOfX:rotationOfXFig1}.
\imageFigure{../figures/GAelectrodynamics/rotationOfXFig1}{Rotation in a plane.}{fig:rotationOfX:rotationOfXFig1}{0.3}

Such a complex exponential only rotates vectors that lie in the plane of the bivector, and commute with vector (or vector components) that lie outside of the rotational plane (\cref{problem:normalMult:1}).  This means that conjugate complex exponentials applied from both sides,
rotate the components of the vector that lie in the rotational plane, but leave the normal components unaltered.  The desired expression of a \R{N} rotation \footnote{Also the structure of a Pauli matrix rotation and quaternionic rotations} has the ``sandwich'' structure

\boxedEquation{eqn:SimpleProducts2:840}{
\Bx' =
e^{-i\theta/2} \Bx e^{i \theta/2},
}

where \( i \) is the unit bivector for the plane of rotation.  When the vector has no components outside of the plane, single sided rotations can be used, which is often convienient

\begin{equation}\label{eqn:SimpleProducts2:980}
\Bx' = \Bx e^{i \theta} = e^{-i\theta} \Bx.
\end{equation}

\paragraph{Vector product.}

The product of two 2D vectors is illustrative.  Let

\begin{dmath}\label{eqn:SimpleProducts2:500}
\begin{aligned}
   \Bx &= x_1 \Be_1 + x_2 \Be_2 \\
   \By &= y_1 \Be_1 + y_2 \Be_2
\end{aligned},
\end{dmath}

and consider their product
\begin{dmath}\label{eqn:SimpleProducts2:520}
\Bx \By
=
\lr{ x_1 \Be_1 + x_2 \Be_2 }
\lr{ y_1 \Be_1 + y_2 \Be_2 }
=
x_1 y_1 \Be_1 \Be_1 + x_2 y_1 \Be_2 \Be_1
+
x_1 y_2 \Be_1 \Be_2 + x_2 y_2 \Be_2 \Be_2
=
x_1 y_1
- x_2 y_1 \Be_1 \Be_2
+ x_1 y_2 \Be_1 \Be_2
+ x_2 y_2
=
x_1 y_1 + x_2 y_2
+ \lr{ x_1 y_2 - x_2 y_1 } \Be_1 \Be_2.
\end{dmath}

The vector product has a scalar and a bivector component, where the scalar component is completely symmetric, whereas the bivector component is completely antisymmetric.  Observe that the scalar selection from the vector product is the dot product.  A name is required for the bivector (grade-2) selection from this product, and it is called the wedge product \( \Bx \wedge \By \), an operation that has to be examined in more depth.  With such a definition, the vector product can be written as

%\begin{dmath}\label{eqn:SimpleProducts2:540}
\boxedEquation{eqn:SimpleProducts2:540}{
\Bx \By
= \Bx \cdot \By + \Bx \wedge \By,
}
%\end{dmath}

where

\begin{dmath}\label{eqn:SimpleProducts2:560}
\begin{aligned}
\Bx \cdot \By &\equiv \gpgradezero{\Bx\By} = x_1 y_1 + x_2 y_2 \\
\Bx \wedge \By &\equiv \gpgradetwo{\Bx\By} =
\begin{vmatrix}
   x_1 & x_2 \\
   y_1 & y_2
\end{vmatrix}
   \Be_1 \Be_2. \\
\end{aligned}
\end{dmath}

Because the wedge product is completely antisymmetric, it must be true that

\begin{dmath}\label{eqn:SimpleProducts2:580}
\By \wedge \Bx = -\Bx \wedge \By,
\end{dmath}

so
\begin{dmath}\label{eqn:SimpleProducts2:600}
\By \Bx
= \By \cdot \Bx + \By \wedge \Bx
= \Bx \cdot \By - \Bx \wedge \By.
\end{dmath}

Taken together \cref{eqn:SimpleProducts2:540} and \cref{eqn:SimpleProducts2:600} allow for a construction of a coordinate free form of both the dot and wedge products

%\begin{dmath}\label{eqn:SimpleProducts2:620}
\boxedEquation{eqn:SimpleProducts2:620}{
\begin{aligned}
\Bx \cdot \By   &= \inv{2}\lr{ \Bx \By + \By \Bx } \\
\Bx \wedge \By  &= \inv{2}\lr{ \Bx \By - \By \Bx }.
\end{aligned}
}
%\end{dmath}

These highlight the symmetric and antisymmetric nature of the respective dot and wedge products.  Some authors will use \cref{eqn:SimpleProducts2:620} as the definitions of the dot and wedge products instead of defining them in terms of grade selection.  Grade selection is preferred here since it allows for a generalization of the wedge product to multiple vectors in higher degree spaces in a particularily simple way, and also allows for the generalization of the dot and wedge products with higher order geometric structures to be discussed.

\paragraph{Area}

It was previously claimed that the pseudoscalar \( \Be_1 \Be_2 \) could be interpretted as an oriented (signed) area.  Because \( \Be_1 \cdot \Be_2 = 0 \), this vector product is also equal to the wedge

\begin{dmath}\label{eqn:SimpleProducts2:640}
\Be_1 \Be_2 = \Be_1 \cdot \Be_2 +
\Be_1 \wedge \Be_2
=
\Be_1 \wedge \Be_2.
\end{dmath}

Recall that the area of the parallopiped spanned by two vectors in a two dimensional space is given by the absolute value of

\begin{dmath}\label{eqn:SimpleProducts2:660}
\begin{vmatrix}
   x_1 & x_2 \\
   y_1 & y_2
\end{vmatrix},
\end{dmath}

a factor that was also found in the coordinate expansion of the wedge product (\cref{eqn:SimpleProducts2:560}).  It is therefore natural to interpret the wedge product as an oriented area.  In \cref{fig:orientedParallelogram:orientedParallelogramFig1} are examples of the wedge product oriented area interpretation.
\imageFigure{../figures/GAelectrodynamics/orientedParallelogramFig1}{Oriented area interpretation of \( \Bv_1 \wedge \Bv_2 \) and \( \Bv_2 \wedge \Bv_1 \).}{fig:orientedParallelogram:orientedParallelogramFig1}{0.3}
In higher dimensonal spaces, the bivector factor not only encodes a sign for this area, but also its orientation in space.  The wedge product will be seen to encode that orientation without introducing a normal direction for the spanning plane, a nice feature in higher dimensional spaces where a single normal direction is ambiguous.

Because there are many possible pairs of generating vectors for any given bivector, any oriented area in a given plane with a specified area are all equally valid interpretations of a bivector.  This is illustrated in \cref{fig:orientedAreasVariety:orientedAreasVarietyFig1}.
\imageFigure{../figures/GAelectrodynamics/orientedAreasVarietyFig1}{Different shape representations of a given bivector.}{fig:orientedAreasVariety:orientedAreasVarietyFig1}{0.2}

\paragraph{Projection and rejection}

An immediate application of the vector product is the computation of the projective and rejective components of a vector with respect to another.  This follows by a unit vector factoring of unity \( \ucap^2 = 1 \),

\begin{dmath}\label{eqn:SimpleProducts2:680}
\Bx =
\Bx \ucap \ucap
=
\lr{ \Bx \ucap } \ucap
=
\lr{ \Bx \cdot \ucap + \Bx \wedge \ucap } \ucap
=
\lr{ \Bx \cdot \ucap } \ucap + \lr{ \Bx \wedge \ucap } \ucap.
\end{dmath}

The first term \( \lr{ \Bx \cdot \ucap } \ucap \) is the familiar projection along the direction \( \ucap \).  Since both sides of the equation must be a vector, this means that the multivector

\begin{dmath}\label{eqn:SimpleProducts2:700}
\lr{ \Bx \wedge \ucap } \ucap
=\Bx - \lr{ \Bx \cdot \ucap } \ucap,
\end{dmath}

is also a vector.  Subtracting the projection from the vector itself is the perpendicular projection, called the \boldTextAndIndex{rejection} in GA literature.  A few of the expected algebraic properties of this multivector rejection expression can be demonstrated.  Recall that the dot product can be computed using scalar grade selection, so

\begin{dmath}\label{eqn:SimpleProducts2:720}
\lr{ \lr{ \Bx \wedge \ucap } \ucap } \cdot \lr{ \ucap \lr{ \Bx \cdot \ucap } }
=
\gpgradezero{ \lr{ \Bx \wedge \ucap } \ucap \ucap \lr{ \Bx \cdot \ucap } }
=
\lr{ \Bx \cdot \ucap }
\gpgradezero{ \Bx \wedge \ucap }
= 0.
\end{dmath}

Here the scalar \( \ucap \ucap \lr{ \Bx \cdot \ucap } = \Bx \cdot \ucap \) was brought outside of the grade selection operator, leaving a scalar selection of a bivector, which is zero by definition.  This shows explicitly that the projection and the rejection are perpendicular.  The pythagorean property of these two vector components can also be checked.  Computing the squared length using \( \Norm{\By}^2 = \By \cdot \By = \By^2 \), the squared length of the projective component is

\begin{dmath}\label{eqn:SimpleProducts2:740}
\lr{ \lr{\Bx \cdot \ucap } \ucap }^2
=
\lr{\Bx \cdot \ucap }^2
=
(x_1 u_1 + x_2 u_2)^2
=
x_1^2 u_1^2 + x_2^2 u_2^2 + 2 x_1 x_2 u_1 u_2.
\end{dmath}

The squared length of the rejective component is
\begin{dmath}\label{eqn:SimpleProducts2:760}
\lr{ \lr{\Bx \wedge \ucap } \ucap }^2
=
-(\Bx \wedge \ucap) \ucap^2 (\Bx \wedge \ucap)
=
-
\lr{\begin{vmatrix}
   x_1 & x_2 \\
   u_1 & u_2
\end{vmatrix}}^2
(\Be_1 \Be_2)^2
=
x_1^2 u_2^2 + x_2^2 u_1^2 - 2 x_1 x_2 u_1 u_2.
\end{dmath}

Adding these together gives

\begin{dmath}\label{eqn:SimpleProducts2:780}
\lr{ \lr{\Bx \cdot \ucap } \ucap }^2 + \lr{ \lr{\Bx \wedge \ucap } \ucap }^2
=
x_1^2 u_1^2 + x_2^2 u_2^2
+x_1^2 u_2^2 + x_2^2 u_1^2
=
x_1^2 ( u_1^2 + u_2^2 )
+
x_2^2 ( u_1^2 + u_2^2 )
=
\Bx^2,
\end{dmath}

recovering the squared length of the vector as expected.  It is generally true in higher dimensions that the projection and rejection can be written as

\begin{dmath}\label{eqn:SimpleProducts2:800}
\begin{aligned}
\Proj_\ucap(\Bx) &= (\Bx \cdot \ucap) \ucap \\
\RejName_\ucap(\Bx) &= (\Bx \wedge \ucap) \ucap.
\end{aligned}
\end{dmath}

The Pythagorean aspect of this statement in higher degree spaces
will be demonstrated later in a coordinate free fashion after some additional identities have been derived.

The unit vector restriction defining the direction of projection and rejection can be relaxed in a compact fashion by introducing the vector \boldTextAndIndex{inverse}, which is always well defined and unique in a Euclidean space

\boxedEquation{eqn:SimpleProducts2:860}{
\inv{\Bu} \equiv \frac{\Bu}{\Bu^2}.
}

Now the projection and rejection onto the direction of \( \Bu \) are

\boxedEquation{eqn:SimpleProducts2:880}{
\begin{aligned}
\Proj_\Bu(\Bx) &= (\Bx \cdot \Bu) \inv{\Bu} \\
\RejName_\Bu(\Bx) &= (\Bx \wedge \Bu) \inv{\Bu}.
\end{aligned}
}
\index{projection}
\index{rejection}

An illustrative example of both projection and rejection is plotted in \cref{fig:projectionAndRejection:projectionAndRejectionFig1}.

\imageFigure{../figures/GAelectrodynamics/projectionAndRejectionFig1}{Projection and rejection illustrated.}{fig:projectionAndRejection:projectionAndRejectionFig1}{0.3}

\makedigression{Wedge and cross product relationships}{
Given that the wedge product has the ``cross product like'' properties \( \Bx \wedge \Bx = 0 \), and \( \Bx \wedge \By = -\By \wedge \Bx \),
and because the \R{3} expression of the rejection is

\begin{equation}\label{eqn:SimpleProducts2:820}
\RejName_\ucap(\Bx) = \Bx - (\Bx \cdot \ucap) \ucap = \ucap \cross (\Bx \cross \ucap),
\end{equation}

which is clearly similar to that of \cref{eqn:SimpleProducts2:800}, the observant reader may see from this expression that the wedge product in \R{3} seems to be related to the cross product in some fashion.  The precise nature of that relationship will be detailed later.
} % digression

\paragraph{Reflection}
\index{reflection}

Computation of the reflection of a vector through the origin, across the direction given by the vector \( \Bu \) (also passing through the origin) can now be expressed compactly.  That is

\begin{dmath}\label{eqn:SimpleProducts2:900}
\Bx'
= \lr{ \Bx \cdot \Bu }\Bu - \lr{ \Bx \wedge \Bu } \inv{\Bu }
= \lr{ \Bx \cdot \Bu - \Bx \wedge \Bu } \inv{\Bu }
= \inv{2} \lr{ \Bx \Bu + \Bu \Bx - \Bx \Bu + \Bu \Bx } \inv{\Bu },
\end{dmath}

or
\boxedEquation{eqn:SimpleProducts2:920}{
\Bx' = \Bu \Bx \inv{\Bu}.
}

An illustration of the geometry of reflection is provided in \cref{fig:reflection:reflectionFig1}.

\imageFigure{../figures/GAelectrodynamics/reflectionFig1}{Reflection}{fig:reflection:reflectionFig1}{0.3}

\paragraph{Solution of linear systems}

Various types of linear systems can be solved using the wedge product.  An illustrative example is that of the intersection of two lines as illustrated in \cref{fig:intersectionOfLines:intersectionOfLinesFig1}.

\imageFigure{../figures/GAelectrodynamics/intersectionOfLinesFig1}{Intersection of two lines.}{fig:intersectionOfLines:intersectionOfLinesFig1}{0.3}

In parametric form, the lines in this problem are

\begin{dmath}\label{eqn:SimpleProducts2:1000}
\begin{aligned}
\Br_1(s) &= \Ba_0 + s( \Ba_1 - \Ba_2 ) \\
\Br_2(t) &= \Bb_0 + t( \Bb_1 - \Bb_2 ),
\end{aligned}
\end{dmath}

so the solution, if it exists, is found at the point satisfying the equality

\begin{dmath}\label{eqn:SimpleProducts2:1020}
\Ba_0 + s( \Ba_1 - \Ba_2 ) = \Bb_0 + t( \Bb_1 - \Bb_2 ).
\end{dmath}

With
\begin{dmath}\label{eqn:SimpleProducts2:1040}
\begin{aligned}
\Bu_1 &= \Ba_1 - \Ba_2 \\
\Bu_2 &= \Bb_1 - \Bb_2 \\
\Bd &= \Ba_0 - \Bb_0,
\end{aligned}
\end{dmath}

so the desired equation to solve is

\begin{dmath}\label{eqn:SimpleProducts2:1060}
\Bd + s \Bu_1 = t \Bu_2.
\end{dmath}

In \R{3} this problem can solved using the cross product (\cref{problem:crossProductLinearIntersectionProblem:1}), however, this can be solved more generally as a 
bivector equation by wedging both sides with either \( \Bu_1 \) or \( \Bu_2 \)

\begin{dmath}\label{eqn:SimpleProducts2:1080}
\begin{aligned}
\Bd \wedge \Bu_1 &= t \Bu_2 \wedge \Bu_1 \\
\Bd \wedge \Bu_2 + s \Bu_1 \wedge \Bu_2 &= 0,
\end{aligned}
\end{dmath}

In \R{2} these equations have a solution if \( \Bu_1 \wedge \Bu_2 \ne 0 \), and in \R{N} these have solutions if the bivectors on each sides of the equations describe the same plane.  Put another way, these have solutions when \( s \) and \( t \) are scalars and

\begin{dmath}\label{eqn:SimpleProducts2:1100}
\begin{aligned}
s &= \frac{\Bu_2 \wedge \Bd}{\Bu_1 \wedge \Bu_2} \\
t &= \frac{\Bu_1 \wedge \Bd}{\Bu_1 \wedge \Bu_2}.
\end{aligned}
\end{dmath}

For \R{2}, 
where the wedge product can be expressed as a (unit bivector scaled) determinant, this is precisely the Cramer's rule solution of the equivalent matrix equation.
