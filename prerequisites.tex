
\makedefinition{Vector space.}{def:prerequisites:vectorspace}{
A vector space is a set \( V \), the elements of which are called vectors, which has an addition and scalar multiplication operations, such that 
for all vectors \( \Bx, \By, \Bz \in V \) and scalars \( a, b \in \bbR \),
the following axioms are satisfied

\begin{tcolorbox}[tab2,tabularx={X|Y},title=Vector space axioms.,boxrule=0.5pt]
    Addition is closed. & \( \Bx + \By \in V \) \\ \hline
    (Scalar) multiplication is closed. & \( a \Bx \in V \) \\ \hline
    Addition is associative. & \( (\Bx + \By) + \Bz = \Bx + (\By + \Bz) \) \\ \hline
    Addition is commutative. & \( \By + \Bx = \Bx + \By \) \\ \hline
    There exists a zero element \( 0 \in V \).  & \( \Bx + 0 = \Bx \) \\ \hline
    For any \( \Bx \in V \) there exists a negative additive inverse \( -\Bx \in V \). & \( \Bx + (-\Bx) = 0 \) \\ \hline
    (Scalar) multiplication is distributive.  & \( a( \Bx + \By ) = a \Bx + a \By \), \( (a + b)\Bx = a \Bx + b\Bx \) \\ \hline
    (Scalar) multiplication is associative. & \( (a b) \Bx = a ( b \Bx ) \) \\ \hline
    There exists a multiplicative identity \( 1 \). & \( 1 \Bx = \Bx \) \\ \hline
\end{tcolorbox}
}

All of the vector spaces used in this book will also be real dot product spaces.  Vectors \( \Bx, \By \in V \) for a vector space \( V \) have an associated dot product \( \Bx \cdot \By = \By \cdot \Bx \) that defines the notion of perpendicularity for the space.  The generalization of geometric algebras to (complex) inner product spaces where the inner product operator is order dependent, that is \( \innerprod{\Bx}{\By} \ne \innerprod{\By}{\Bx} \) (in general), is known as Clifford Algebra.  That abstraction will not be required for any of the physical applications to be considered.

In the study of electromagnetic waves, scalar multiples of vectors will be allowed to be complex.  However, the underlying direction vectors will be assumed to be always real, and no notion of complex conjugatation will be built into the dot product itself.

% TODO: rework dimension by adding:
% - span
% - linear dependence
% - linear independence
% - subspace
% - (then finally) dimension
% FIXME: this is now the only chicken and egg problem left (normal used before its definition).  Probably have to define linear independence to resolve.
\makedefinition{Dimension}{dfn:multivector:dimension}{
   The dimension of a vector space is a count of the number of normal directions in that space.
} % definition

Only finite dimensional vector spaces will be used in this book.

\makedefinition{Basis and coordinates}{dfn:multivector:basis}{
   If \( N \) is the dimension of a vector space \( V \), a set of \( N \) vectors \( B = \setlr{ \Ba_1, \Ba_2, \cdots , \Ba_N } \) is a basis for that vector space, if it is possible to form any vector \( \Bx \in V \) as a linear combination of those vectors \( \Ba_k \).  That is, there exists scalars \( c_k \) such that for any \( \Bx \in V \)

\begin{equation*}
   \Bx = \sum_{k = 1}^N c_k \Ba_k.
\end{equation*}

The numbers \( (c_1, c_2, \cdots, c_N ) \) are referred to as the coordinates of the vector \( \Bx \) with respect to the basis \( B \).
}

While it is common, especially in engineering, to represent a vector \( \Bx \) as a tuple or column vector, say,

\begin{dmath}\label{eqn:multivector:180}
   \Bx =
\begin{bmatrix}
   c_1 \\
   c_2 \\
   \vdots \\
   c_N \\
\end{bmatrix},
\end{dmath}

where the basis associated with the vector is implied, this will not be done here.  Instead, whenever coordinates are used, they will be explicitly paired with their associated basis vectors.

\makedefinition{Standard basis, and inner product properties}{dfn:multivector:standardbasis}{
   Any vector space \( V \) used in this book will be assumed to have been generated from a basis \( \setlr{ \Be_1, \Be_2, \cdots, \Be_N } \), associated with a dot product that has the properties

\begin{enumerate}
   \item \( \Be_i \cdot \Be_i = \pm 1 \).
   \item \( \Be_i \cdot \Be_j = 0 \) for any \( i \ne j \).
\end{enumerate}

Such a basis will called a standard basis.  When these dot products are always positive, the vector space is referred to as a Euclidean vector space.
}

There are many possible standard bases sets.  In \R{3}, it is conventional to refer to \( \Be_1, \Be_2, \Be_3 \) as the standard bases elements if these represent the directions of the x, y, and z directions respectively.  Unless otherwise noted \( \Be_k \) refers to the direction vector for the k-th direction in a standard basis for that space.

The only non-Euclidean vector space of interest in this book (for relativistic material), has a Minkowski dot product.  For such a space, the standard basis elements will be labelled \( \setlr{ \gamma_0, \gamma_1, \gamma_2, \gamma_3 } \), where for \( i \in [1,3] \), \( \gamma_0 \cdot \gamma_0 = \pm 1 = -\gamma_i \cdot \gamma_i \).  The positive sign convention will be used.

\makedefinition{Norm-squared}{dfn:multivector:norm}{
   The squared norm of a vector \( \Bx \) is defined as

\begin{dmath}\label{eqn:multivector:200}
   \Norm{\Bx}^2 = \Bx \cdot \Bx.
\end{dmath}

This quantity need not be positive.
}

\makedefinition{Length}{dfn:multivector:length}{
   The length of a vector \( \Bx \) is defined as 

\begin{equation*}
\Norm{\Bx} = 
\sqrt{\Abs{ \Norm{\Bx}^2 }}.
\end{equation*}
}

A vector space with an associated norm based length is called a normed vector space.  Any dot product space is also a normed vector space.

\makedefinition{Unit vector}{dfn:multivector:unitvector}{
   A vector \( \Bx \) is called a unit vector if its length is one.
} % definition

A unit vector \( \xcap \) may be generated from any vector \( \Bx \) that has a non-zero squared norm by computing

\begin{dmath}\label{eqn:multivector:220}
\xcap = \frac{\Bx}{\sqrt{\Abs{\Norm{\Bx}^2}}}.
\end{dmath}

\makedefinition{Normal}{dfn:multivector:normal}{
   Two vectors are normal, or perpendicular, if their dot product is zero.
}

\makedefinition{Orthonormal}{dfn:multivector:orthonormal}{
   A set of vectors \( \setlr{ \Bx, \By, \cdots, \Bz } \) is an orthonormal set if all pairs of vectors in that set are normal and are also unit vectors.
} % definition

\subsection{Problems}
\makeproblem{One dimensional multivector space.}{problem:multivector:30}{
   Given \( f(x) = e^x \) and \( g(x) = x^2 \), and scalars \( a,b \in \bbR \) determine whether the set
   \( V = \setlr{ a f(x) + b g(x) } \) is a vector space.
} % problem

\makeproblem{Pauli matrix vector space.}{problem:multivector:20}{
The Pauli matrices are defined as

\begin{dmath}\label{eqn:multivector:160}
\begin{aligned}
   \sigma_1 &= \PauliX \\
   \sigma_2 &= \PauliY \\
   \sigma_3 &= \PauliZ.
\end{aligned}
\end{dmath}

\makesubproblem{}{problem:multivector:20:a}
Given any scalars \( a, b, c \in \bbR \), show that the set \( V = \setlr{ a \sigma_1 + b \sigma_2 + c \sigma_3 } \) is a vector space, and determine the required form of the unit multiplicative identity element.

\makesubproblem{}{problem:multivector:20:b}

Show that \( \sigma_k^2 = I \), where \( I \) is the 2x2 identity matrix, and that \( \sigma_k \sigma_j = -\sigma_k \sigma_j \) for all \( k \ne j \).

\makesubproblem{}{problem:multivector:20:c}

Using the results of \partref{problem:multivector:20:b}, show that
\( \lr{ a \sigma_x + b \sigma_y + c \sigma_z }^2 = (a^2 + b^2 + c^2) I \), where \( I \) is the 2x2 identity matrix.
%This shows that the Pauli matrices are an example \R{3} basis for which the contraction axiom is built right into the representation.
} % problem

\makeproblem{Explicit squared norm}{problem:multivector:60}{
   Given a coordinate representation of a vector with respect to a standard basis
\begin{dmath}\label{eqn:multivector:240}
   \Bx = \sum_{i = 1}^N x_i \Be_i,
\end{dmath}

show that the squared norm is
\begin{dmath}\label{eqn:multivector:260}
   \Norm{\Bx}^2 = \Bx \cdot \Bx = \sum_{i = 1}^N x_i^2 (\Be_i \cdot \Be_i).
\end{dmath}

Observe that for a Euclidean vector space this is the squared length in the Pythagorean sense.
}

\makeproblem{Null vector}{problem:multivector:80}{
Given a two dimensional non-Euclidean vector space with basis elements satisfying 
\( \gamma_0 \cdot \gamma_0 = 1 = -\gamma_1 \cdot \gamma_1 \), construct a vector that has a squared
norm of 0.  Such a vector is called a null vector.
%   \Bx = \gamma_0 + \gamma_1,
}

%%%\makeproblem{}{problem:multivector:50}{
%%%The most general definition of an Euclidean norm satisfies all of the properties
%%%
%%%\begin{enumerate}
%%%   \item \( \Norm{\Bx} \ge 0 \), and \( \Norm{\Bx} = 0 \iff \Bx = 0 \).
%%%   \item \( \Norm{a \Bx} = \Abs{a} \Norm{\Bx} \).
%%%   \item \( \Norm{\Bx + \By} \le \Norm{\Bx} + \Norm{\By} \).
%%%\end{enumerate}
%%%
%%%If the coordinates of a vector with respect to the standard basis are \( x_i \) then show that the Euclidean norm defined in
%%%that the Pythagorean norm
%%%\begin{equation*}
%%%\Norm{\Bx}^2 = \sum_{i = 1}^N x_i^2,
%%%\end{equation*}
%%%
%%%satisfies these properties.
%%%} % problem
%%%
